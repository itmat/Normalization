#!/usr/bin/env perl
#use warnings;
my $USAGE =  "\nUsage: run_normalization --sample_dirs <file of sample_dirs> --loc <s> --unaligned <file of fa/fqfiles> --samfilename <s> --cfg <cfg file> [options]

where:
--sample_dirs <file of sample_dirs> : is a file of sample directories with alignment output without path
--loc <s> : /path/to/directory with the sample directories
--unaligned <file of fa/fqfiles> : is a file with the full path of input forward fa or forward fq files
--samfilename <s> : is the name of aligned sam file (e.g. RUM.sam, Aligned.out.sam) 
--cfg <cfg file> : is a cfg file for the study

OPTIONS:
     [pipeline options]
     By default, the pipeline will run through the steps in PART1 and pause (recommended).
     You will have a chance to check the following before resuming:
      (1) number of reads you will have after normalization 
          - modify the list of sample directories accordingly.
      (2) percent high expressers
          - use -cutoff_highexp <n> option to set/change the highexpresser cutoff value.

     -part1_part2 : Use this option if you want to run steps in PART1 and PART2 without pausing. 
     -part2 : Use this option to resume the pipeline at PART2. You may edit the <file of sample_dirs> file 
               and/or change the highexpresser cutoff value.

     [resume options]
     You may not change the normalization parameters with resume option.
     -resume : Use this if you have a job that crashed or stopped.
               Runs job that has already been initialized or partially run after the last completed step.
               It may repeat the last completed step.
     -resume_at \"<step>\" : Use this if you have a job that crashed or stopped.
                             This resumes at \"<step>\".
                             **make sure full step name (found in log file) is given in quotes**
                             (e.g. \"1    \"allsteps.get_total_num_reads\"\")

     [data type]
     -se : set this if the data are single end, otherwise by default it will assume it's a paired end data
     -fa : set this if the unaligned files are in fasta format 
     -fq : set this if the unaligned files are in fastq format 
     -gz : set this if the unaligned files are compressed

     [normalization parameters]
     -cutoff_highexp <n> : is cutoff % value to identify highly expressed genes/exons/introns.
                           the script will consider genes/exons/introns with gene/exon/intronpercents greater than n(%) as high expressers,
                           report the list of highly expressed genes/exons and remove the reads that map to those genes/exons/introns.
                           (Default = 100; with the default cutoff, genes/exons/introns expressed >5% will be reported)
     -cutoff_lowexp <n> : is cutoff counts to identify low expressers in the final spreadsheets (exon, intron and junc).
                          the script will consider features with sum of counts for all samples less than <n> as low expressers
                          and remove them from all samples for the final spreadsheets.
                          (Default = 0; this will remove features with sum of counts = 0)

     -percent <n> : is used for generating master list of exons and genes.
                    by default, 10% of the size of first and last exon of each transcript
                    will be added to the start of the first and the end of the last exon, respectively.
                    use this option to change the percentage <n>. (<n> has to be a number between 0-100)

     [exon-intron-junction normalization only]
     -novel_off : set this if you DO NOT want to generate/use a study-specific master list of exons 
                  (By default, the pipeline will add inferred exons to the list of exons)
     -min <n> : is minimum size of inferred exon for get_novel_exons.pl script (Default = 10)
     -max <n> : is maximum size of inferred exon for get_novel_exons.pl script (Default = 2000)
     -depthE <n> : the pipeline splits filtered sam files into 1,2,3...n exonmappers and downsamples each separately.
                   (Default = 20)
     -depthI <n> : the pipeline splits filtered sam files into 1,2,3...n intronmappers and downsamples each separately.
                   (Default = 10)
     -h : print usage 

";


if(@ARGV < 10) {
    die $USAGE;
}

my $required = 0;
my $unaligned = 0;
my $count_b = 0;
my $count_r = 0;
my $se = "";
my $unaligned_z = "";
my $min = 10;
my $max = 2000;
my $cutoff_he = 100;
my $percent = 10;
my $filter_high_expressers = "false";
my $i_exon = 20;
my $i_intron = 10;
my $filter_low_expressers = "false";
my $novel = "true";
my $shfile_name = "runall_normalization.sh";
my $resume = "false";
my $resume_at = "false";
my ($sample_dir, $LOC, $unaligned_file, $samfilename, $unaligned_type, $cfg_file, $cutoff_temp, $last_step);
my $part2 = "false";
for(my $i=0; $i<@ARGV; $i++) {
    $option_found = "false";
    if ($ARGV[$i] eq '-h'){
	$option_found = "true";
	die $USAGE;
    }
    if ($ARGV[$i] eq '-part1_part2'){
	$option_found = "true";
	$shfile_name = "runall_normalization_part1_part2.sh";
	$count_b++;
    }
    if ($ARGV[$i] eq '-resume'){
	$option_found = "true";
	$resume = "true";
	$count_r++;
    }
    if ($ARGV[$i] eq '-resume_at'){
	$option_found = "true";
	$resume = "true";
	$count_r++;
	$resume_at = "true";
	$last_step = $ARGV[$i+1];
	if ($last_step =~ /^$/){
	    die "you need to provide -resume_at \"<step>\".\n";
	}
	$i++;
    }
    if ($ARGV[$i] eq '-part2'){
        $option_found = "true";
	$part2 = "true";
	$shfile_name = "runall_normalization_part2.sh";
	$count_b++;
    }
    if ($ARGV[$i] eq '--sample_dirs'){
	$option_found = "true";
	$sample_dir = $ARGV[$i+1];
	if ($sample_dir =~ /^-/ | $sample_dir eq ""){
	    die "\nplease provide <file of sample_dirs> for --sample_dirs\n";
	}
	$i++;
	$required++;
    }
    if ($ARGV[$i] eq '-novel_off'){
	$option_found = "true";
	$novel = "false";
    }
    if ($ARGV[$i] eq '--loc'){
	$option_found = "true";
        $LOC = $ARGV[$i+1];
	if ($LOC =~ /^-/ | $LOC eq ""){
	    die "\nplease provide '/path/to/directory with the sample directories' for --loc\n";
	}
        $i++;
	$required++;
    }
    if ($ARGV[$i] eq '--unaligned'){
	$option_found = "true";
        $unaligned_file = $ARGV[$i+1];
	if ($unaligned_file =~ /^-/ | $unaligned_file eq ""){
	    die "\nplease provide <file of fa/fqfiles> for --unaligned\n";
	}
        $i++;
	$required++;
    }
    if ($ARGV[$i] eq '--samfilename'){
	$option_found = "true";
	$samfilename = $ARGV[$i+1];
	if ($samfilename =~ /^-/ | $samfilename eq ""){
	    die "\nplease provide the 'name of aligned samfile' for --samfilename\n";
	}
	$i++;
	$required++;
    }
    if ($ARGV[$i] eq '--cfg'){
	$option_found = "true";
	$cfg_file = $ARGV[$i+1];
	if ($cfg_file =~ /^-/ | $cfg_file eq ""){
	    die "\nplease provide <cfg file> for --cfg\n";
	}
	$i++;
	$required++;
    }
    if ($ARGV[$i] eq '-se'){
        $option_found = "true";
	$se = "-se";
    }
    if ($ARGV[$i] eq '-fa'){
        $option_found = "true";
	$unaligned++;
	$unaligned_type = "-fa";
    }
    if ($ARGV[$i] eq '-fq'){
        $option_found = "true";
	$unaligned++;
	$unaligned_type = "-fq";
    }
    if ($ARGV[$i] eq '-gz'){
        $option_found = "true";
        $unaligned_z = "-gz";
    }
    if($ARGV[$i] eq '-min') {
	$min = $ARGV[$i+1];
	$i++;
	$option_found = "true";
        if ($min !~ /(\d+$)/ ){
            die "-min <n> : <n> needs to be a number\n";
        }
    }
    if($ARGV[$i] eq '-max') {
	$max = $ARGV[$i+1];
	$i++;
	$option_found = "true";
        if ($max !~ /(\d+$)/ ){
            die "-max <n> : <n> needs to be a number\n";
        }
    }
    if($ARGV[$i] eq '-cutoff_highexp') {
        $cutoff_he = $ARGV[$i+1];
        $i++;
        $option_found = "true";
	$filter_high_expressers = "true";
        if ($cutoff_he !~ /(\d+$)/ ){
            die "-cutoff_highexp <n> : <n> needs to be a number\n";
        }
    }
    if ($ARGV[$i] eq '-percent'){
	$percent = $ARGV[$i+1];
	$i++;
	$option_found = "true";
	if (($percent !~ /(\d+$)/) || ($percent > 100) || ($percent < 0) ){
            die "-percent <n> : <n> needs to be a number between 0-100\n";
        }
    }
    if ($ARGV[$i] eq '-depthE'){
	$i_exon = $ARGV[$i+1];
	if ($i_exon !~ /(\d+$)/ ){
	    die "-depthE <n> : <n> needs to be a number\n";
	}
	$i++;
	$option_found = "true";
    }
    if ($ARGV[$i] eq '-depthI'){
	$i_intron = $ARGV[$i+1];
	if ($i_intron !~ /(\d+$)/ ){
	    die "-depthI <n> : <n> needs to be a number\n";
	}
	$i++;
	$option_found = "true";
    }
    if($ARGV[$i] eq '-cutoff_lowexp') {
        $cutoff_temp = $ARGV[$i+1];
        $i++;
        $option_found = "true";
        $filter_low_expressers = "true";
        if ($cutoff_temp !~ /(\d+$)/ ){
            die "-cutoff_lowexp <n> : <n> needs to be a number\n";
        }
    }
    if($option_found eq "false") {
        die "option \"$ARGV[$i]\" was not recognized.\n";
    }
}
if ($required ne '5'){
    die "please specify the required parameters: --sample_dirs, --loc, --unaligned, --samfilename and --cfg\n";
}
if ($unaligned ne '1'){
    die "you have to specify the type of your unaligned files: '-fa' or '-fq'\n"
}
if ($count_b > 1){
    die "you can only set one of the following options: -part1_part2, -part2\n";
}
if ($count_r > 1){
    die "you can only set one of the following options: -resume, -resume_at \"<step>\"\n";
}

my $dirs = `wc -l $sample_dir`;
my @a = split(" ", $dirs);
my $num_samples = $a[0];
my $cutoff_le = 0;
if ($filter_low_expressers eq "true"){
    $cutoff_le = $cutoff_temp;
}
$LOC =~ s/\/$//;
my @fields = split("/", $LOC);
my $last_dir = $fields[@fields-1];
my $study_dir = $LOC;
$study_dir =~ s/$last_dir//;
my $study = $fields[@fields-2];

my $GNORM = "false";
my $EIJ = "false";
#check_config file
unless (-e $cfg_file){
    die "ERROR: cannot find file \"$cfg_file\". please provide a cfg file for the study\n";
}

&parse_config_file ($cfg_file, \%Config);

use Cwd 'abs_path';
my $norm_script_dir = abs_path($0);
$norm_script_dir =~ s/\/run_normalization//;

my $normcnt = 0;
if ($GENE_NORM =~ /true/i){
    $GNORM = "true";
    $normcnt++;
}
if ($EXON_INTRON_JUNCTION_NORM =~ /^true/i){
    $EIJ = "true";
    $normcnt++;
}

if ($normcnt == 0){
    die "ERROR: Please select a type of Normalization you'd like to use (# 0. NORMALIZTION and DATA TYPE - [A] Normalization Type in your cfg file \"$cfg_file\")\n\n";
}
my $geneinfo;
if ($EIJ eq "true"){
    $geneinfo = $GENE_INFO_FILE;
    unless (-e $geneinfo){
	die "ERROR: cannot find file \"$geneinfo\"\nYou need to provide [2] gene information file for Exon-Intron-Junction Normalization (# 2. GENE INFO in your cfg file \"$cfg_file\")\n\n";
    }
}
my $genome = $GENOME_FA;
unless (-e $genome){
    die "ERROR: cannot find file \"$genome\"\nYou need to provide [1] genome sequence one-line fasta file (# 3. FA and FAI in your cfg file \"$cfg_file\")\n\n";
}
my $fai = $GENOME_FAI;
unless (-e $fai){
    die "ERROR: cannot find file \"$fai\"\nYou need to provide [2] index file (# 3. FA and FAI in your cfg file \"$cfg_file\")\n\n";
}
my $annot;
if ($EIJ eq "true"){
    $annot = $ANNOTATION_FILE;
    unless (-e $annot){
	die "ERROR: cannot find file \"$annot\"\nYou need to provide [3] Annotation file for [Exon-Intron-Junction Normalization] (# 2. GENE INFO in your cfg file \"$cfg_file\")\n\n"; 
    }
}
my $ensGene;
if ($GNORM eq "true"){
    $ensGene = $ENSGENES_FILE;
    unless (-e $ensGene){
	die "ERROR: cannot find file \"$ensGene\"\nYou need to provide [1] Gene information file for [Gene Normalization] (# 2. GENE INFO in your cfg file \"$cfg_file\")\n\n";
    }
}


my $strand_info = "";
my $strand_info_sam2cov = "";
if ($STRANDED =~ /^true/i){
    $strand_info_sam2cov = "-str";
    my $strand_flag = 0;
    if ($FWD =~ /^true/i){
	$strand_flag++;
	$strand_info = "-str_f";
    }
    if ($REV =~ /^true/i){
	$strand_flag++;
	$strand_info = "-str_r";
    }
    if ($strand_flag ne "1"){
	die "Please specify the read orientation. (# 0. NORMALIZTION and DATA TYPE - [B] Stranded Data in your cfg file \"$cfg_file\")\n\n";
    }
}
my $sam2cov = "false";
my $sam2cov_loc;
if ($SAM2COV =~ /^true/i){
    $sam2cov = "true";
    my $num_cov = 0;
    unless (-e $SAM2COV_LOC){
	die "You need to provide sam2cov location. (# 4. DATA VISUALIZATION in your cfg file \"$cfg_file\")\n";
    }
    $sam2cov_loc = $SAM2COV_LOC;
    if ($RUM =~ /^true/i){
	$aligner = "-rum";
	$num_cov++;
    }
    if ($STAR =~ /^true/i){
	$aligner = "-star";
	$num_cov++;
    }
    if ($num_cov ne '1'){
	die "Please specify which aligner was used. (# 4. DATA VISUALIZATION in your cfg file \"$cfg_file\")\n\n";
    }
}
my $delete_int_sam = "true";
my $convert_sam2bam = "false";
my $gzip_cov = "false";
if ($DELETE_INT_SAM ne ""){
    if ($DELETE_INT_SAM =~ /^true/i){
	$delete_int_sam = "true";
    }
    if ($DELETE_INT_SAM=~ /^false/i){
	$delete_int_sam = "false";
    }
}
if ($CONVERT_SAM2BAM ne ""){
    if ($CONVERT_SAM2BAM =~ /^true/i){
	$convert_sam2bam = "true";
    }
    if ($CONVERT_SAM2BAM =~ /^false/i){
	$convert_sam2bam= "false";
    }
}
if ($GZIP_COV ne ""){
    if ($GZIP_COV =~ /^true/i){
	$gzip_cov = "true";
    }
    if ($GZIP_COV =~ /^false/i){
	$gzip_cov = "false";
    }
}

my $lsf = "false";
my $sge = "false";
my $other = "false";
my $num_cluster = 0;
my ($batchjobs,  $jobname, $status, $request, $queue_4G,  $queue_6G, $queue_10G, $queue_15G, $queue_30G, $queue_45G, $queue_60G, $submit, $c_option, $maxjobs);
if ($SGE_CLUSTER =~ /^true/i){
    $num_cluster++;
    if ($QUEUE_NAME_4G_sge eq "" | $QUEUE_NAME_6G_sge eq "" | $QUEUE_NAME_10G_sge eq "" |  $QUEUE_NAME_15G_sge eq "" | $QUEUE_NAME_30G_sge eq "" | $QUEUE_NAME_45G_sge eq "" | $QUEUE_NAME_60G_sge eq "" | $MAX_JOBS_sge eq ""){
        die "ERROR: please provide all required CLUSTER INFO for SGE_CLUSTER in the config file \"$cfg_file\"\n";
    }
    else{
	$batchjobs = "qsub -cwd";
	$jobname = "-N";
	$status = "qstat -r";
	$request = "-l h_vmem=";
	$queue_4G = $QUEUE_NAME_4G_sge;
	$queue_6G = $QUEUE_NAME_6G_sge;
	$queue_10G = $QUEUE_NAME_10G_sge;
	$queue_15G = $QUEUE_NAME_15G_sge;
	$queue_30G = $QUEUE_NAME_30G_sge;
	$queue_45G = $QUEUE_NAME_45G_sge;
	$queue_60G = $QUEUE_NAME_60G_sge;
	$submit = "-sge";
	$sge = "true";
	$c_option = $submit;
	$maxjobs = $MAX_JOBS_sge;
    }
}
if ($LSF_CLUSTER =~ /^true/i){
    $num_cluster++;
    if ($QUEUE_NAME_4G_lsf eq "" | $QUEUE_NAME_6G_lsf eq "" | $QUEUE_NAME_10G_lsf eq "" |  $QUEUE_NAME_15G_lsf eq "" | $QUEUE_NAME_30G_lsf eq "" | $QUEUE_NAME_45G_lsf eq "" | $QUEUE_NAME_60G_lsf eq "" | $MAX_JOBS_lsf eq ""){
        die "ERROR: please provide all required CLUSTER INFO for LSF_CLUSTER in the config file \"$cfg_file\"\n";
    }
    else{
	$batchjobs = "bsub";
	$jobname = "-J";
	$status = "bjobs -w";
	$request = "-q";
	$queue_4G = $QUEUE_NAME_4G_lsf;
	$queue_6G = $QUEUE_NAME_6G_lsf;
	$queue_10G = $QUEUE_NAME_10G_lsf;
	$queue_15G = $QUEUE_NAME_15G_lsf;
	$queue_30G = $QUEUE_NAME_30G_lsf;
	$queue_45G = $QUEUE_NAME_45G_lsf;
	$queue_60G = $QUEUE_NAME_60G_lsf;
	$submit = "-lsf";
	$lsf = "true";
	$c_option = $submit;
	$maxjobs = $MAX_JOBS_lsf;
    }
}
if ($OTHER_CLUSTER =~ /^true/i){
    $num_cluster++;
    if ($SUBMIT_BATCH_JOBS eq "" | $JOB_NAME_OPTION eq "" | $CHECK_STATUS_FULLNAME eq "" | $REQUEST_RESOURCE_OPTION eq "" | $QUEUE_NAME_4G eq "" | $QUEUE_NAME_6G eq "" | $QUEUE_NAME_10G eq "" |  $QUEUE_NAME_15G eq "" | $QUEUE_NAME_30G eq "" | $QUEUE_NAME_45G eq "" | $QUEUE_NAME_60G eq "" | $MAX_JOBS eq ""){
	die "ERROR: please provide all required CLUSTER INFO for OTHER_CLUSTER in the config file \"$cfg_file\"\n";
    }
    else {
	$batchjobs = $SUBMIT_BATCH_JOBS;
	$jobname = $JOB_NAME_OPTION;
	$status = $CHECK_STATUS_FULLNAME;
	$request = $REQUEST_RESOURCE_OPTION;
	$queue_4G = $QUEUE_NAME_4G;
	$queue_6G = $QUEUE_NAME_6G;
	$queue_10G = $QUEUE_NAME_10G;
	$queue_15G = $QUEUE_NAME_15G;
	$queue_30G = $QUEUE_NAME_30G;
	$queue_45G = $QUEUE_NAME_45G;
	$queue_60G = $QUEUE_NAME_60G;
	$submit = "-other";
	$other = "true";
	$maxjobs = $MAX_JOBS;
    }
}
if ($num_cluster ne '1'){
    die "ERROR: please specify which cluster you're using in your configuration file \"$cfg_file\"\n";
}

my $shdir = $study_dir . "shell_scripts";
my $logdir = $study_dir . "logs";
my $logfile = $logdir . "/$study.run_normalization.log";
unless (-d $shdir){
    `mkdir $shdir`;}
unless (-d $logdir){
    `mkdir $logdir`;}

#check if the sam files exist
open(IN, $sample_dir) or die "cannot find file \"$sample_dir\"\n";
while (my $line = <IN>){
    chomp($line);
    my $file_loc = "$LOC/$line/$samfilename";
    unless (-e $file_loc){
	die "ERROR: SAM file \"$file_loc\" does not exist. Please double check --sample_dirs, --loc, and --samfilename\n";
    }
}
close(IN);
#check if the fq/fa files exist
open(IN, $unaligned_file) or die "cannot find file \"$unaligned_file\"\n";
while (my $line = <IN>){
    chomp($line);
    unless (-e $line){
	die "ERROR: Unaligned file \"$line\" does not exist.\n";
    }
}
close(IN);
#if resume option used, check if the log file exists
if (($resume eq "true") && ($resume_at eq "false")){
    unless (-e $logfile){
	die "ERROR: Log file \"$logfile\" does not exist. Please use -resume_at \"<step>\" option to resume.\n\n";
    }
}
my $runall_shfile = $shdir . "/" . $shfile_name;
open(SH, ">$runall_shfile");
if ($resume_at eq "true"){
    $argv = join(" ", &args2shell(@ARGV));
}
else{
    $argv = join(" ", @ARGV);
}
print SH "perl $norm_script_dir/runall_normalization.pl $argv";
close(SH);

my ($p2_I, $p2_E);
if ($part2 eq "true"){
#if -part2 is set, check to make sure runall_normalization.sh file exists.
    unless (-e "$shdir/runall_normalization.sh"){
	die "ERROR: cannot find file \"$shdir/runall_normalization.sh\".\n-part2 option cannot be used. please run the pipeline using default pipeline setting first.\n";
    }
#if -depthE and/or -depthI is greater than before
    my $default_sh = `cat $shdir/runall_normalization.sh`;
    my $part2_sh = `cat $runall_shfile`;
    my $def_E = 20;
    my $def_I = 10;
    my $res_E = 20;
    my $res_I = 10;
    if ($default_sh =~ /-depthE/){
	$default_sh =~ /-depthE\ (\d+)/;
	$def_E = $1;
	if ($def_E =~ /^$/){
	    $def_E = 20;
	}
    }
    if ($default_sh =~ /-depthI/){
	$default_sh =~ /-depthI\ (\d+)/;
	$def_I = $1;
	if ($def_I =~ /^$/){
	    $def_I = 10;
	}
    }
    if ($part2_sh =~ /-depthE/){
	$part2_sh =~ /-depthE\ (\d+)/;
	$p2_E = $1;
	if ($p2_E =~ /^$/){
	    $p2_E = 20;
	}
    }
    else{
	$p2_E = 20;
    }
    if ($part2_sh =~ /-depthI/){
	$part2_sh =~ /-depthI\ (\d+)/;
	$p2_I = $1;
	if ($p2_I =~ /^$/){
	    $p2_I = 10;
	}
    }
    else{
	$p2_I = 10;
    }
    if (($p2_E > $def_E)){
	die "ERROR: Check \"-depthE <n>\" option. <n> cannot be greater than $def_E.\n";
    }
    if (($p2_I > $def_I)){
	die "ERROR: Check \"-depthI <n>\" option. <n> cannot be greater than $def_I.\n";
    }
    #if -part2 is set and $novel is true, check and make sure study-specific master list of exon exists.
    if ($novel eq "true"){
	unless (-e "$LOC/master_list_of_exons.$study.txt"){
	    die "ERROR: cannot find file \"$LOC/master_list_of_exons.$study.txt\".\nCreate a study-specific master list of exons by running step 3)-B. Get Novel Exons.\n";
	}
    }
}

my @s = split(" ", $status);
my $stat = $s[0];
while(qx{$stat | wc -l} > $maxjobs){
    sleep(10);
}
`$batchjobs $jobname "$study.RUNALL_NORMALIZATION" -o $logdir/$study.runall_normalization.out -e $logdir/$study.runall_normalization.err < $runall_shfile`;

sub args2shell{
    local (@argv) = @_;
    local $" = '\' \'';
    local (@margv);

    @margv = map { s/'/'\\''/g; $_ } @argv;
    return "\'@margv\'" if @margv;
    return undef;   
} 

sub parse_config_file () {
    my ($File, $Config) = @_;
    open(CONFIG, "$File") or die "ERROR: Config file not found : $File\n";
    while (my $config_line = <CONFIG>) {
	chomp($config_line);
        $config_line =~ s/^\s*//;
        $config_line =~ s/\s*$//;
        if ( ($config_line !~ /^#/) && ($config_line ne "") ){
	    my ($Name, $Value) = split(/\s*=\s*/, $config_line);
	    if ($Value =~ /^"/){
		$Value =~ s/^"//;
		$Value =~ s/"$//;
	    }
	    $Config{$Name} = $Value;
	    $$Name = $Value;
	}
    }
}
